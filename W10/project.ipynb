{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70de5895-00e1-4aa2-97d3-827ee91bf435",
   "metadata": {},
   "source": [
    "# BIG DATA PROJECT - HADOOP HEROES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c84e6d5-1da8-43e3-a344-3ca6a8c9440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fa0a2f-cf73-47d3-9fb2-05c8cdca56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/05 19:03:11 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.21.10.196 instead (on interface eth0)\n",
      "23/11/05 19:03:11 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 19:03:11 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session WebUI Port: 4040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"ISM6562 Spark Project\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Let's get the SparkContext object. It's the entry point to the Spark API. It's created when you create a sparksession\n",
    "sc = spark.sparkContext  \n",
    "sc.setLogLevel(\"ERROR\") # only display errors (not warnings)\n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run), \n",
    "# this spark session webUI will be on a different port than the default (4040). One way to \n",
    "# identify this part is with the following line. If there was only one spark session running, \n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)\n",
    "\n",
    "# It's best if you find that the port number displayed below is not 4040, then you should shut down all other spark sessions and \n",
    "# run this code again. If you don't, you may have trouble accessing the data in the spark-warehouse directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f58cef-4d8c-4b74-8713-d63de7a24b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://linux:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ISM6562 Spark Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f15b4f92fb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e41e11-fa59-4d53-9f7a-e2091bf85e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c4e1f87-3255-4a1b-83cf-264ae69e9d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|   w10_db|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"show databases\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a3b8ec2-c6bb-41e2-9b12-12d95562d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21889ead-2042-4028-ad39-fd9808dfa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data to warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ac0be0c-7a49-46a7-a5da-86f73012d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+\n",
      "|       1|    02-01-2022 00:06|     02-01-2022 00:19|              1|          5.4|         138|         252|       17.0| 1.75|       3.9|       23.45|       1.25|\n",
      "|       1|    02-01-2022 00:38|     02-01-2022 00:55|              1|          6.4|         138|          41|       21.0| 1.75|       0.0|        30.1|       1.25|\n",
      "|       1|    02-01-2022 00:03|     02-01-2022 00:26|              1|         12.5|         138|         200|       35.5| 1.75|       0.0|        44.6|       1.25|\n",
      "|       2|    02-01-2022 00:08|     02-01-2022 00:28|              1|         9.88|         239|         200|       28.0|  0.5|       0.0|        34.8|        0.0|\n",
      "|       2|    02-01-2022 00:06|     02-01-2022 00:33|              1|        12.16|         138|         125|       35.5|  0.5|      8.11|       48.66|       1.25|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip = spark.read.csv('data/yellow_tripdata_2022-02.csv', header=True, inferSchema=True);\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "trip.show(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3914abf7-b679-4cab-8cdb-e2668c512a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Assuming your DataFrame is named 'df', and you want to create a new column 'TIP_STATUS'\n",
    "trip = trip.withColumn(\"TIP_STATUS\", F.when(trip[\"tip_amount\"] > 0, 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6e0b405-da7c-4099-83b7-39948682d305",
   "metadata": {},
   "source": [
    "trip.createOrReplaceTempView(\"trip_tmp_view\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaafad85-2875-4247-a146-068a042ba6fa",
   "metadata": {},
   "source": [
    "df = spark.sql(\"SELECT * FROM trip_tmp_view\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a98dd2cb-4aba-4d68-93a9-b296e245d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a922f776-61e2-4ab7-874c-e2e6e3003162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f20392b7-0843-4b65-bf78-4bddee7952b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save table in spark data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85741792-3de4-4145-90eb-f22efc92da1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS w10_db;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94e7d65c-6e3d-4f05-b567-a0b77994f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trip.write.mode(\"overwrite\").saveAsTable(\"w10_db.trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99387fbb-709d-4276-be6b-02cb23ddf23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='boston', catalog='spark_catalog', namespace=['w10_db'], description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='trip', catalog='spark_catalog', namespace=['w10_db'], description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables('w10_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ab828ad-44e4-4ef2-9f3c-314e952af18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+\n",
      "|       2|    02-01-2022 20:44|     02-01-2022 21:08|              1|         5.74|         107|           7|       20.5|  0.5|      4.86|       29.16|        0.0|         1|\n",
      "|       1|    02-01-2022 20:35|     02-01-2022 20:44|              1|          1.3|         230|         229|        7.0|  3.0|       0.0|        10.8|        0.0|         0|\n",
      "|       2|    02-01-2022 20:11|     02-01-2022 20:33|              1|         4.37|          79|         236|       18.0|  0.5|      4.36|       26.16|        0.0|         1|\n",
      "|       2|    02-01-2022 20:49|     02-01-2022 20:52|              1|         0.46|         162|         229|        4.0|  0.5|       5.0|        12.8|        0.0|         1|\n",
      "|       1|    02-01-2022 20:33|     02-01-2022 20:37|              1|          0.6|         211|         113|        4.5|  3.0|      1.65|        9.95|        0.0|         1|\n",
      "|       1|    02-01-2022 20:48|     02-01-2022 21:06|              1|          2.3|         170|          48|       12.5|  3.0|      3.26|       19.56|        0.0|         1|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:12|              1|          1.7|         236|         237|        8.5|  3.0|      3.05|       15.35|        0.0|         1|\n",
      "|       1|    02-01-2022 20:49|     02-01-2022 20:58|              1|          1.8|         263|         237|        9.0|  3.0|      2.55|       15.35|        0.0|         1|\n",
      "|       2|    02-01-2022 20:04|     02-01-2022 20:15|              2|         2.32|         161|         113|       10.0|  0.5|      2.48|       16.28|        0.0|         1|\n",
      "|       2|    02-01-2022 20:35|     02-01-2022 20:48|              2|         3.42|         113|         237|       12.5|  0.5|       2.0|        18.3|        0.0|         1|\n",
      "|       2|    02-01-2022 20:55|     02-01-2022 21:08|              2|         2.26|         161|         236|       11.0|  0.5|      2.22|       17.02|        0.0|         1|\n",
      "|       2|    02-01-2022 20:58|     02-01-2022 21:28|              4|         5.72|         249|         181|       22.5|  0.5|      5.26|       31.56|        0.0|         1|\n",
      "|       2|    02-01-2022 20:03|     02-01-2022 20:08|              1|          0.6|         236|         263|        5.0|  0.5|       2.2|        11.0|        0.0|         1|\n",
      "|       2|    02-01-2022 20:18|     02-01-2022 20:22|              1|         0.83|         263|         141|        5.0|  0.5|       0.0|         8.8|        0.0|         0|\n",
      "|       2|    02-01-2022 20:27|     02-01-2022 20:34|              1|          1.5|         236|         239|        7.0|  0.5|      2.16|       12.96|        0.0|         1|\n",
      "|       2|    02-01-2022 20:39|     02-01-2022 20:46|              1|         1.42|         239|         237|        7.0|  0.5|       0.0|        10.8|        0.0|         0|\n",
      "|       2|    02-01-2022 20:59|     02-01-2022 21:08|              2|         1.96|          43|         151|        9.0|  0.5|       3.2|        16.0|        0.0|         1|\n",
      "|       2|    02-01-2022 20:15|     02-01-2022 20:23|              1|         2.11|         234|         229|        9.0|  0.5|      2.56|       15.36|        0.0|         1|\n",
      "|       2|    02-01-2022 20:38|     02-01-2022 20:45|              1|         1.21|         161|         141|        6.5|  0.5|      2.06|       12.36|        0.0|         1|\n",
      "|       2|    02-01-2022 19:58|     02-01-2022 20:04|              1|         1.06|         107|          90|        6.5|  0.5|       1.0|        11.3|        0.0|         1|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM w10_db.trip\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c09ea736-9104-4097-a4f2-41d75bc65da7",
   "metadata": {},
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84444499-fbef-43c9-ab00-b545d33071c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- TIP_STATUS: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dea49ca8-e16e-4698-9a8a-b51a0678e931",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df = df.withColumn(\"tpep_pickup_datetime\", to_timestamp(df[\"tpep_pickup_datetime\"], \"MM-dd-yyyy HH:mm\"))\n",
    "df = df.withColumn(\"tpep_dropoff_datetime\", to_timestamp(df[\"tpep_dropoff_datetime\"], \"MM-dd-yyyy HH:mm\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be9d5a50-0931-4304-a702-c86d5234296b",
   "metadata": {},
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74341ba-46c9-4752-8d96-ebb26618d89b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1548517e-19e9-41df-bce8-c4471d7991f6",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import IntegerType,BooleanType,DateType, StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e0caa93-85b0-4bc0-b975-ef1b8820364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "30c55d99-cc59-4b0a-8fd6-6c7b8eb12565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# Use StringIndexer to convert the categorical columns to hold numerical data\n",
    " \n",
    "tpep_pickup_datetime_indexer = StringIndexer(inputCol='tpep_pickup_datetime',outputCol='tpep_pickup_datetime_index',handleInvalid='keep')\n",
    "tpep_dropoff_datetime_indexer = StringIndexer(inputCol='tpep_dropoff_datetime',outputCol='tpep_dropoff_datetime_index',handleInvalid='keep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40c2bccc-058b-4dc2-8a14-ac3bfd13452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'tip_amount',\n",
       " 'total_amount',\n",
       " 'airport_fee',\n",
       " 'TIP_STATUS']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c88769-ebc3-42a2-8d87-70ea1baa2575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2b65b4ea-0d8d-4850-aef1-a2030c0ed05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Vector assembler is used to create a vector of input features\n",
    " \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'passenger_count',\n",
    "        'trip_distance',\n",
    "        'airport_fee',\n",
    "        'PULocationID',\n",
    "        'DOLocationID',\n",
    "        'tpep_dropoff_datetime_index',\n",
    "        'tpep_pickup_datetime_index'\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac89eb16-1e0b-4619-9b42-2a7fcd086213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Pipeline is used to pass the data through indexer and assembler simultaneously. Also, it helps to pre-rocess the test data\n",
    "# in the same way as that of the train data\n",
    "# https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    " \n",
    "pipe = Pipeline(stages=[\n",
    "    tpep_dropoff_datetime_indexer,\n",
    "    tpep_pickup_datetime_indexer,\n",
    "    assembler\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3cb15d7-225c-430b-9d65-9a931e72bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fitted_pipe=pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "be48a194-1248-4058-a9ef-4a1b5d347fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|tpep_dropoff_datetime_index|tpep_pickup_datetime_index|            features|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:03|              1|          0.7|         142|          48|        5.0|  3.5|       0.0|         9.3|        0.0|         0|                     7009.0|                    5668.0|[1.0,0.7,0.0,142....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:03|              1|          0.9|         236|          43|        5.0|  3.5|       0.0|         9.3|        0.0|         0|                     7009.0|                    5668.0|[1.0,0.9,0.0,236....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:04|              0|          0.9|         230|         186|        5.0|  3.0|       2.0|        10.8|        0.0|         1|                     5920.0|                    5668.0|[0.0,0.9,0.0,230....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:04|              2|          0.7|          43|         236|        4.5|  3.5|       0.0|         8.8|        0.0|         0|                     5920.0|                    5668.0|[2.0,0.7,0.0,43.0...|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:06|              1|          1.2|          68|         158|        6.0|  3.0|      1.95|       11.75|        0.0|         1|                     5393.0|                    5668.0|[1.0,1.2,0.0,68.0...|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data=fitted_pipe.transform(train_data)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af9ce14b-d5f3-48c9-bd3e-be95a808e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|tpep_dropoff_datetime_index|tpep_pickup_datetime_index|            features|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:05|              1|          0.9|         162|         137|        6.0|  3.0|      1.95|       11.75|        0.0|         1|                     3451.0|                    5668.0|[1.0,0.9,0.0,162....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:06|              1|          1.1|         162|         186|        6.5|  3.0|      2.05|       12.35|        0.0|         1|                     5393.0|                    5668.0|[1.0,1.1,0.0,162....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:07|              1|          1.1|         237|         236|        7.0|  3.0|      1.25|       12.05|        0.0|         1|                     5921.0|                    5668.0|[1.0,1.1,0.0,237....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:08|              1|          1.5|         162|         142|        8.0|  3.0|       2.2|        14.0|        0.0|         1|                     6217.0|                    5668.0|[1.0,1.5,0.0,162....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:09|              1|          1.0|          90|         158|        7.0|  3.0|      2.15|       12.95|        0.0|         1|                     3894.0|                    5668.0|[1.0,1.0,0.0,90.0...|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data=fitted_pipe.transform(test_data)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "48d921e8-4d16-4a96-aa30-eb4cb80bf999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For those interested in utilizing the ML/AI power of Tensorflow with Spark....\n",
    "# https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-distributor\n",
    "\n",
    "# In this course, we'll use the SparkML (admitedely, it's not as powerful as Tensorflow, but \n",
    "# it's easy to use and demonstrate ML on a Spark Cluster)\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression(labelCol='fare_amount')\n",
    "fit_model = lr_model.fit(train_data.select(['features','fare_amount']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bc99b7a-4e23-442b-ab45-a8db0e16dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|tpep_dropoff_datetime_index|tpep_pickup_datetime_index|            features|        prediction|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+------------------+\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:05|              1|          0.9|         162|         137|        6.0|  3.0|      1.95|       11.75|        0.0|         1|                     3451.0|                    5668.0|[1.0,0.9,0.0,162....| 7.399546488862595|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:06|              1|          1.1|         162|         186|        6.5|  3.0|      2.05|       12.35|        0.0|         1|                     5393.0|                    5668.0|[1.0,1.1,0.0,162....| 7.787183912796198|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:07|              1|          1.1|         237|         236|        7.0|  3.0|      1.25|       12.05|        0.0|         1|                     5921.0|                    5668.0|[1.0,1.1,0.0,237....| 7.724357224644789|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:08|              1|          1.5|         162|         142|        8.0|  3.0|       2.2|        14.0|        0.0|         1|                     6217.0|                    5668.0|[1.0,1.5,0.0,162....| 8.834481439749123|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:09|              1|          1.0|          90|         158|        7.0|  3.0|      2.15|       12.95|        0.0|         1|                     3894.0|                    5668.0|[1.0,1.0,0.0,90.0...|  7.62814232598533|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:09|              1|          1.2|         107|         114|        7.5|  3.0|      2.25|       13.55|        0.0|         1|                     3894.0|                    5668.0|[1.0,1.2,0.0,107....| 8.190035101192478|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:10|              2|          2.0|         230|         158|        9.0|  3.0|      2.55|       15.35|        0.0|         1|                     2510.0|                    5668.0|[2.0,2.0,0.0,230....| 10.38961308849689|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:11|              1|          2.2|         249|         163|       10.0|  3.5|       0.0|        14.3|        0.0|         0|                     4626.0|                    5668.0|[1.0,2.2,0.0,249....|10.792362030688146|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:18|              1|          5.1|         140|         125|       18.5|  3.0|      4.45|       26.75|        0.0|         1|                     7011.0|                    5668.0|[1.0,5.1,0.0,140....| 18.43530535371559|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:24|              1|          3.6|         239|         161|       17.0|  3.0|      4.15|       24.95|        0.0|         1|                     9086.0|                    5668.0|[1.0,3.6,0.0,239....|14.270334539871596|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:07|              1|          0.7|         230|          50|        5.5|  3.0|      2.75|       12.05|        0.0|         1|                     5921.0|                    7340.0|[1.0,0.7,0.0,230....|  6.72933649995036|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:09|              1|          1.0|         143|         163|        7.0|  3.5|      2.25|       13.55|        0.0|         1|                     3894.0|                    7340.0|[1.0,1.0,0.0,143....| 7.588554305811612|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:11|              1|          2.6|         162|         238|       10.5|  3.0|      4.25|       18.55|        0.0|         1|                     4626.0|                    7340.0|[1.0,2.6,0.0,162....|11.782528472527638|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:11|              6|          1.1|         164|         100|        8.0|  3.0|       1.0|        12.8|        0.0|         1|                     4626.0|                    7340.0|[6.0,1.1,0.0,164....|  7.85291917340197|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:13|              1|          2.8|         161|         238|       10.5|  3.0|       1.7|        16.0|        0.0|         1|                     5394.0|                    7340.0|[1.0,2.8,0.0,161....|  12.2712340695602|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:14|              1|          2.1|         107|         231|       10.0|  3.0|      3.45|       17.25|        0.0|         1|                     6218.0|                    7340.0|[1.0,2.1,0.0,107....|10.351415122760704|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:18|              1|          3.1|         263|         170|       13.0|  3.0|       1.0|        17.8|        0.0|         1|                     7011.0|                    7340.0|[1.0,3.1,0.0,263....|13.016233178473795|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:22|              1|          4.0|         113|         239|       14.5|  3.0|      3.65|       21.95|        0.0|         1|                     8733.0|                    7340.0|[1.0,4.0,0.0,113....|15.280469486605552|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:51|              1|         19.3|         132|         230|       52.0| 3.75|      2.82|       59.37|       1.25|         1|                     7751.0|                    7340.0|[1.0,19.3,1.25,13...| 56.07280295696022|\n",
      "|       1|    02-01-2022 20:02|     02-01-2022 20:24|              1|          4.2|         236|          68|       17.5|  3.0|      4.25|       25.55|        0.0|         1|                     9086.0|                    2692.0|[1.0,4.2,0.0,236....|15.997323740409612|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = fit_model.transform(test_data)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "090f20b8-ee80-4a14-9cd9-63ec188ec069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|fare_amount|        prediction|\n",
      "+-----------+------------------+\n",
      "|        6.0| 7.399546488862595|\n",
      "|        6.5| 7.787183912796198|\n",
      "|        7.0| 7.724357224644789|\n",
      "|        8.0| 8.834481439749123|\n",
      "|        7.0|  7.62814232598533|\n",
      "|        7.5| 8.190035101192478|\n",
      "|        9.0| 10.38961308849689|\n",
      "|       10.0|10.792362030688146|\n",
      "|       18.5| 18.43530535371559|\n",
      "|       17.0|14.270334539871596|\n",
      "|        5.5|  6.72933649995036|\n",
      "|        7.0| 7.588554305811612|\n",
      "|       10.5|11.782528472527638|\n",
      "|        8.0|  7.85291917340197|\n",
      "|       10.5|  12.2712340695602|\n",
      "|       10.0|10.351415122760704|\n",
      "|       13.0|13.016233178473795|\n",
      "|       14.5|15.280469486605552|\n",
      "|       52.0| 56.07280295696022|\n",
      "|       17.5|15.997323740409612|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(['fare_amount','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18991818-9b72-4028-929d-2be8ae96ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b42ebec-34ca-4a2f-9ccb-faf9bb75b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_results = fit_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ca17849a-b081-4be0-aece-2405fedf6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "| -1.3995464888625948|\n",
      "| -1.2871839127961984|\n",
      "| -0.7243572246447894|\n",
      "| -0.8344814397491227|\n",
      "| -0.6281423259853298|\n",
      "| -0.6900351011924784|\n",
      "| -1.3896130884968905|\n",
      "|  -0.792362030688146|\n",
      "| 0.06469464628440846|\n",
      "|  2.7296654601284036|\n",
      "| -1.2293364999503602|\n",
      "| -0.5885543058116118|\n",
      "| -1.2825284725276376|\n",
      "|  0.1470808265980299|\n",
      "| -1.7712340695601991|\n",
      "| -0.3514151227607041|\n",
      "|-0.01623317847379...|\n",
      "| -0.7804694866055524|\n",
      "|  -4.072802956960217|\n",
      "|  1.5026762595903875|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "725744d0-4aa8-4c2d-baf7-8fa73f2f04f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:     6.074\n",
      "Ex Var:  98.854\n",
      "MAE:      2.119\n",
      "MSE:     36.899\n",
      "RMSE:     6.074\n",
      "R2:       0.729\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'RMSE:':7s} {test_results.rootMeanSquaredError:>7.3f}\")\n",
    "print(f\"{'Ex Var:':7s} {test_results.explainedVariance:>7.3f}\")\n",
    "print(f\"{'MAE:':7s} {test_results.meanAbsoluteError:>7.3f}\")\n",
    "print(f\"{'MSE:':7s} {test_results.meanSquaredError:>7.3f}\")\n",
    "print(f\"{'RMSE:':7s} {test_results.rootMeanSquaredError:>7.3f}\")\n",
    "print(f\"{'R2:':7s} {test_results.r2:>7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7d57d-ef27-47cc-a7bc-9542ec9f15f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0890541-2b97-41d9-8c69-250659feb7fc",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b943f2-b663-4603-a6ad-a141a27d86bb",
   "metadata": {},
   "source": [
    "Whether a taxi trip results in a tip or not. Here's a modified version of your code for logistic regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cbbe45ee-aae5-4797-8f0e-54debc8b0b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dc4fb7ff-20ea-46dc-bb08-a3f4ec53da5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- TIP_STATUS: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "97e53bfa-8531-4051-bbe5-59d8f13a1f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define categorical and numeric columns\n",
    "categorical_columns = ['VendorID', 'PULocationID', 'DOLocationID']\n",
    "numeric_columns = ['passenger_count', 'trip_distance', 'extra', 'airport_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e7e94d93-6855-4647-adce-d7b0492a5c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StringIndexer to convert the categorical columns to hold numerical data\n",
    "VendorID_indexer=StringIndexer(inputCol='VendorID', outputCol='VendorID_index',handleInvalid='keep')\n",
    "PULocationID_indexer=StringIndexer(inputCol='PULocationID', outputCol='PULocationID_index',handleInvalid='keep')\n",
    "DOLocationID_indexer=StringIndexer(inputCol='DOLocationID', outputCol='DOLocationID_index',handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2493a4a4-3ac0-48bb-82ae-1c959545ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3ef4735e-c771-4e6b-a230-25fecf173fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_encoder = OneHotEncoder(\n",
    "    inputCols=[\n",
    "        'VendorID_index',\n",
    "        'PULocationID_index',\n",
    "        'DOLocationID_index'\n",
    "    ], \n",
    "    outputCols= [\n",
    "        'VendorID_vec',\n",
    "        'PULocationID_vec',\n",
    "        'DOLocationID_vec'],\n",
    "    handleInvalid='keep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "78226192-e00d-4295-bea7-a925ae733254",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'VendorID_vec',\n",
    "        'PULocationID_vec',\n",
    "        'DOLocationID_vec'\n",
    "        ],\n",
    "    outputCol=\"features_log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "49bbe838-0bc3-4971-ac48-9c5a6e52cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model=LogisticRegression(labelCol='TIP_STATUS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6dd49bc7-450e-4d8e-8792-d6f7409a0c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    stages=[\n",
    "        VendorID_indexer,\n",
    "    PULocationID_indexer,\n",
    "    DOLocationID_indexer,\n",
    "        data_encoder,\n",
    "        assembler,\n",
    "        lr_model\n",
    "    ]\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0fc333-c3cd-4b54-9dce-a1aedf207a11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24d36941-4676-402a-8731-ac1048c2df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# run the pipeline\n",
    "fit_model=pipe.fit(train_data)\n",
    "\n",
    "# Store the results in a dataframe\n",
    "results_log = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cdede77f-62ee-4ee6-84a2-449a3715cc04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|TIP_STATUS|prediction|\n",
      "+----------+----------+\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         0|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_log.select(['TIP_STATUS','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52f2c96-00cd-4d8c-b90b-c58bdadc68c1",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9de1af74-6b2b-41b0-829b-340d7671b8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='TIP_STATUS',metricName='areaUnderROC')\n",
    "\n",
    "AUC = AUC_evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4e148657-85a9-49e6-8206-ee1ddc2728fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the curve is 0.5357832354964459\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under the curve is {}\".format(AUC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e1343562-2722-4c4b-a66e-b98b9b6e831a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='TIP_STATUS',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f7bbe49f-ca0b-413c-9a85-b64f5930e1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The area under the PR curve is 0.7740905851574635\n"
     ]
    }
   ],
   "source": [
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fdd103-d998-4369-bf7d-69e55edf9c84",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "ab8bd694-fe40-48a6-8924-33d6ea909529",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "ACC_evaluator = MulticlassClassificationEvaluator(  #  Multiclass or Binary, the accuracy is calculated in the same way.\n",
    "    labelCol=\"TIP_STATUS\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = ACC_evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "78c7b303-8763-4ed1-b68e-8737f8962351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model is 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"The accuracy of the model is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "db3314a3-df46-452c-b9af-d0d020f24a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d09e94ba-d89a-4375-a6da-3b3ccc5b6638",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m y_pred\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[0;32m----> 7\u001b[0m cnf_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/utils/_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    212\u001b[0m         )\n\u001b[1;32m    213\u001b[0m     ):\n\u001b[0;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    224\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:326\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    232\u001b[0m     {\n\u001b[1;32m    233\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m     y_true, y_pred, \u001b[38;5;241m*\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    243\u001b[0m ):\n\u001b[1;32m    244\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute confusion matrix to evaluate the accuracy of a classification.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \n\u001b[1;32m    246\u001b[0m \u001b[38;5;124;03m    By definition a confusion matrix :math:`C` is such that :math:`C_{i, j}`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[38;5;124;03m    (0, 2, 1, 1)\u001b[39;00m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 326\u001b[0m     y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not supported\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/sklearn/metrics/_classification.py:93\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     90\u001b[0m     y_type \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y_type) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification metrics can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt handle a mix of \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m targets\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m     95\u001b[0m             type_true, type_pred\n\u001b[1;32m     96\u001b[0m         )\n\u001b[1;32m     97\u001b[0m     )\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# We can't have more than one value on y_type => The set is no more needed\u001b[39;00m\n\u001b[1;32m    100\u001b[0m y_type \u001b[38;5;241m=\u001b[39m y_type\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "y_true = results.select(\"TIP_STATUS\")\n",
    "y_true = y_true.toPandas()\n",
    " \n",
    "y_pred = results.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    " \n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efad836-e5a9-4a6b-8e5e-1da3ecdc33d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
