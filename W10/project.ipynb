{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70de5895-00e1-4aa2-97d3-827ee91bf435",
   "metadata": {},
   "source": [
    "# BIG DATA PROJECT - HADOOP HEROES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c84e6d5-1da8-43e3-a344-3ca6a8c9440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35fa0a2f-cf73-47d3-9fb2-05c8cdca56e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/05 20:26:46 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.21.10.196 instead (on interface eth0)\n",
      "23/11/05 20:26:46 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/05 20:26:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Session WebUI Port: 4040\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"ISM6562 Spark Project\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "# Let's get the SparkContext object. It's the entry point to the Spark API. It's created when you create a sparksession\n",
    "sc = spark.sparkContext  \n",
    "sc.setLogLevel(\"ERROR\") # only display errors (not warnings)\n",
    "\n",
    "# note: If you have multiple spark sessions running (like from a previous notebook you've run), \n",
    "# this spark session webUI will be on a different port than the default (4040). One way to \n",
    "# identify this part is with the following line. If there was only one spark session running, \n",
    "# this will be 4040. If it's higher, it means there are still other spark sesssions still running.\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)\n",
    "\n",
    "# It's best if you find that the port number displayed below is not 4040, then you should shut down all other spark sessions and \n",
    "# run this code again. If you don't, you may have trouble accessing the data in the spark-warehouse directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8f58cef-4d8c-4b74-8713-d63de7a24b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://linux:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>ISM6562 Spark Project</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fec9c36f970>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0e41e11-fa59-4d53-9f7a-e2091bf85e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c4e1f87-3255-4a1b-83cf-264ae69e9d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|   w10_db|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=spark.sql(\"show databases\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a3b8ec2-c6bb-41e2-9b12-12d95562d381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21889ead-2042-4028-ad39-fd9808dfa98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data to warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ac0be0c-7a49-46a7-a5da-86f73012d810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+\n",
      "|       1|    02-01-2022 00:06|     02-01-2022 00:19|              1|          5.4|         138|         252|       17.0| 1.75|       3.9|       23.45|       1.25|\n",
      "|       1|    02-01-2022 00:38|     02-01-2022 00:55|              1|          6.4|         138|          41|       21.0| 1.75|       0.0|        30.1|       1.25|\n",
      "|       1|    02-01-2022 00:03|     02-01-2022 00:26|              1|         12.5|         138|         200|       35.5| 1.75|       0.0|        44.6|       1.25|\n",
      "|       2|    02-01-2022 00:08|     02-01-2022 00:28|              1|         9.88|         239|         200|       28.0|  0.5|       0.0|        34.8|        0.0|\n",
      "|       2|    02-01-2022 00:06|     02-01-2022 00:33|              1|        12.16|         138|         125|       35.5|  0.5|      8.11|       48.66|       1.25|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trip = spark.read.csv('data/yellow_tripdata_2022-02.csv', header=True, inferSchema=True);\n",
    "\n",
    "# display the first 5 rows of the dataframe\n",
    "trip.show(5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3914abf7-b679-4cab-8cdb-e2668c512a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Assuming your DataFrame is named 'df', and you want to create a new column 'TIP_STATUS'\n",
    "trip = trip.withColumn(\"TIP_STATUS\", F.when(trip[\"tip_amount\"] > 0, 1).otherwise(0))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6e0b405-da7c-4099-83b7-39948682d305",
   "metadata": {},
   "source": [
    "trip.createOrReplaceTempView(\"trip_tmp_view\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaafad85-2875-4247-a146-068a042ba6fa",
   "metadata": {},
   "source": [
    "df = spark.sql(\"SELECT * FROM trip_tmp_view\")\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98dd2cb-4aba-4d68-93a9-b296e245d462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------+\n",
      "|namespace|tableName|isTemporary|\n",
      "+---------+---------+-----------+\n",
      "+---------+---------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tables = spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a922f776-61e2-4ab7-874c-e2e6e3003162",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f20392b7-0843-4b65-bf78-4bddee7952b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save table in spark data warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "85741792-3de4-4145-90eb-f22efc92da1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS w10_db;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e7d65c-6e3d-4f05-b567-a0b77994f076",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "trip.write.mode(\"overwrite\").saveAsTable(\"w10_db.trip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99387fbb-709d-4276-be6b-02cb23ddf23e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='boston', catalog='spark_catalog', namespace=['w10_db'], description=None, tableType='MANAGED', isTemporary=False),\n",
       " Table(name='trip', catalog='spark_catalog', namespace=['w10_db'], description=None, tableType='MANAGED', isTemporary=False)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables('w10_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ab828ad-44e4-4ef2-9f3c-314e952af18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+\n",
      "|       2|    02-01-2022 20:44|     02-01-2022 21:08|              1|         5.74|         107|           7|       20.5|  0.5|      4.86|       29.16|        0.0|         1|\n",
      "|       1|    02-01-2022 20:35|     02-01-2022 20:44|              1|          1.3|         230|         229|        7.0|  3.0|       0.0|        10.8|        0.0|         0|\n",
      "|       2|    02-01-2022 20:11|     02-01-2022 20:33|              1|         4.37|          79|         236|       18.0|  0.5|      4.36|       26.16|        0.0|         1|\n",
      "|       2|    02-01-2022 20:49|     02-01-2022 20:52|              1|         0.46|         162|         229|        4.0|  0.5|       5.0|        12.8|        0.0|         1|\n",
      "|       1|    02-01-2022 20:33|     02-01-2022 20:37|              1|          0.6|         211|         113|        4.5|  3.0|      1.65|        9.95|        0.0|         1|\n",
      "|       1|    02-01-2022 20:48|     02-01-2022 21:06|              1|          2.3|         170|          48|       12.5|  3.0|      3.26|       19.56|        0.0|         1|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:12|              1|          1.7|         236|         237|        8.5|  3.0|      3.05|       15.35|        0.0|         1|\n",
      "|       1|    02-01-2022 20:49|     02-01-2022 20:58|              1|          1.8|         263|         237|        9.0|  3.0|      2.55|       15.35|        0.0|         1|\n",
      "|       2|    02-01-2022 20:04|     02-01-2022 20:15|              2|         2.32|         161|         113|       10.0|  0.5|      2.48|       16.28|        0.0|         1|\n",
      "|       2|    02-01-2022 20:35|     02-01-2022 20:48|              2|         3.42|         113|         237|       12.5|  0.5|       2.0|        18.3|        0.0|         1|\n",
      "|       2|    02-01-2022 20:55|     02-01-2022 21:08|              2|         2.26|         161|         236|       11.0|  0.5|      2.22|       17.02|        0.0|         1|\n",
      "|       2|    02-01-2022 20:58|     02-01-2022 21:28|              4|         5.72|         249|         181|       22.5|  0.5|      5.26|       31.56|        0.0|         1|\n",
      "|       2|    02-01-2022 20:03|     02-01-2022 20:08|              1|          0.6|         236|         263|        5.0|  0.5|       2.2|        11.0|        0.0|         1|\n",
      "|       2|    02-01-2022 20:18|     02-01-2022 20:22|              1|         0.83|         263|         141|        5.0|  0.5|       0.0|         8.8|        0.0|         0|\n",
      "|       2|    02-01-2022 20:27|     02-01-2022 20:34|              1|          1.5|         236|         239|        7.0|  0.5|      2.16|       12.96|        0.0|         1|\n",
      "|       2|    02-01-2022 20:39|     02-01-2022 20:46|              1|         1.42|         239|         237|        7.0|  0.5|       0.0|        10.8|        0.0|         0|\n",
      "|       2|    02-01-2022 20:59|     02-01-2022 21:08|              2|         1.96|          43|         151|        9.0|  0.5|       3.2|        16.0|        0.0|         1|\n",
      "|       2|    02-01-2022 20:15|     02-01-2022 20:23|              1|         2.11|         234|         229|        9.0|  0.5|      2.56|       15.36|        0.0|         1|\n",
      "|       2|    02-01-2022 20:38|     02-01-2022 20:45|              1|         1.21|         161|         141|        6.5|  0.5|      2.06|       12.36|        0.0|         1|\n",
      "|       2|    02-01-2022 19:58|     02-01-2022 20:04|              1|         1.06|         107|          90|        6.5|  0.5|       1.0|        11.3|        0.0|         1|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.sql(\"SELECT * FROM w10_db.trip\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c09ea736-9104-4097-a4f2-41d75bc65da7",
   "metadata": {},
   "source": [
    "spark.sql(\"show tables\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84444499-fbef-43c9-ab00-b545d33071c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- VendorID: integer (nullable = true)\n",
      " |-- tpep_pickup_datetime: string (nullable = true)\n",
      " |-- tpep_dropoff_datetime: string (nullable = true)\n",
      " |-- passenger_count: integer (nullable = true)\n",
      " |-- trip_distance: double (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- fare_amount: double (nullable = true)\n",
      " |-- extra: double (nullable = true)\n",
      " |-- tip_amount: double (nullable = true)\n",
      " |-- total_amount: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- TIP_STATUS: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dea49ca8-e16e-4698-9a8a-b51a0678e931",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df = df.withColumn(\"tpep_pickup_datetime\", to_timestamp(df[\"tpep_pickup_datetime\"], \"MM-dd-yyyy HH:mm\"))\n",
    "df = df.withColumn(\"tpep_dropoff_datetime\", to_timestamp(df[\"tpep_dropoff_datetime\"], \"MM-dd-yyyy HH:mm\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be9d5a50-0931-4304-a702-c86d5234296b",
   "metadata": {},
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74341ba-46c9-4752-8d96-ebb26618d89b",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1548517e-19e9-41df-bce8-c4471d7991f6",
   "metadata": {},
   "source": [
    "from pyspark.sql.types import IntegerType,BooleanType,DateType, StringType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e0caa93-85b0-4bc0-b975-ef1b8820364a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c55d99-cc59-4b0a-8fd6-6c7b8eb12565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# Use StringIndexer to convert the categorical columns to hold numerical data\n",
    " \n",
    "tpep_pickup_datetime_indexer = StringIndexer(inputCol='tpep_pickup_datetime',outputCol='tpep_pickup_datetime_index',handleInvalid='keep')\n",
    "tpep_dropoff_datetime_indexer = StringIndexer(inputCol='tpep_dropoff_datetime',outputCol='tpep_dropoff_datetime_index',handleInvalid='keep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40c2bccc-058b-4dc2-8a14-ac3bfd13452c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VendorID',\n",
       " 'tpep_pickup_datetime',\n",
       " 'tpep_dropoff_datetime',\n",
       " 'passenger_count',\n",
       " 'trip_distance',\n",
       " 'PULocationID',\n",
       " 'DOLocationID',\n",
       " 'fare_amount',\n",
       " 'extra',\n",
       " 'tip_amount',\n",
       " 'total_amount',\n",
       " 'airport_fee',\n",
       " 'TIP_STATUS']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c88769-ebc3-42a2-8d87-70ea1baa2575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b65b4ea-0d8d-4850-aef1-a2030c0ed05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Vector assembler is used to create a vector of input features\n",
    " \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'passenger_count',\n",
    "        'trip_distance',\n",
    "        'airport_fee',\n",
    "        'PULocationID',\n",
    "        'DOLocationID',\n",
    "        'tpep_dropoff_datetime_index',\n",
    "        'tpep_pickup_datetime_index'\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac89eb16-1e0b-4619-9b42-2a7fcd086213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Pipeline is used to pass the data through indexer and assembler simultaneously. Also, it helps to pre-rocess the test data\n",
    "# in the same way as that of the train data\n",
    "# https://spark.apache.org/docs/latest/ml-pipeline.html\n",
    " \n",
    "pipe = Pipeline(stages=[\n",
    "    tpep_dropoff_datetime_indexer,\n",
    "    tpep_pickup_datetime_indexer,\n",
    "    assembler\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3cb15d7-225c-430b-9d65-9a931e72bd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fitted_pipe=pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be48a194-1248-4058-a9ef-4a1b5d347fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|tpep_dropoff_datetime_index|tpep_pickup_datetime_index|            features|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:03|              1|          0.9|         236|          43|        5.0|  3.5|       0.0|         9.3|        0.0|         0|                     4356.0|                    7784.0|[1.0,0.9,0.0,236....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:04|              2|          0.7|          43|         236|        4.5|  3.5|       0.0|         8.8|        0.0|         0|                     4876.0|                    7784.0|[2.0,0.7,0.0,43.0...|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:06|              1|          1.1|         162|         186|        6.5|  3.0|      2.05|       12.35|        0.0|         1|                     4605.0|                    7784.0|[1.0,1.1,0.0,162....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:06|              1|          1.2|          68|         158|        6.0|  3.0|      1.95|       11.75|        0.0|         1|                     4605.0|                    7784.0|[1.0,1.2,0.0,68.0...|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:07|              1|          1.4|         163|         237|        7.0|  3.0|       0.0|        10.8|        0.0|         0|                     5683.0|                    7784.0|[1.0,1.4,0.0,163....|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data=fitted_pipe.transform(train_data)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af9ce14b-d5f3-48c9-bd3e-be95a808e73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|tpep_dropoff_datetime_index|tpep_pickup_datetime_index|            features|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:03|              1|          0.7|         142|          48|        5.0|  3.5|       0.0|         9.3|        0.0|         0|                     4356.0|                    7784.0|[1.0,0.7,0.0,142....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:04|              0|          0.9|         230|         186|        5.0|  3.0|       2.0|        10.8|        0.0|         1|                     4876.0|                    7784.0|[0.0,0.9,0.0,230....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:05|              1|          0.9|         162|         137|        6.0|  3.0|      1.95|       11.75|        0.0|         1|                     5144.0|                    7784.0|[1.0,0.9,0.0,162....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:07|              1|          1.1|         237|         236|        7.0|  3.0|      1.25|       12.05|        0.0|         1|                     5683.0|                    7784.0|[1.0,1.1,0.0,237....|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:08|              1|          1.5|         162|         142|        8.0|  3.0|       2.2|        14.0|        0.0|         1|                     5684.0|                    7784.0|[1.0,1.5,0.0,162....|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data=fitted_pipe.transform(test_data)\n",
    "test_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48d921e8-4d16-4a96-aa30-eb4cb80bf999",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# For those interested in utilizing the ML/AI power of Tensorflow with Spark....\n",
    "# https://github.com/tensorflow/ecosystem/tree/master/spark/spark-tensorflow-distributor\n",
    "\n",
    "# In this course, we'll use the SparkML (admitedely, it's not as powerful as Tensorflow, but \n",
    "# it's easy to use and demonstrate ML on a Spark Cluster)\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression(labelCol='fare_amount')\n",
    "fit_model = lr_model.fit(train_data.select(['features','fare_amount']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5bc99b7a-4e23-442b-ab45-a8db0e16dc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+------------------+\n",
      "|VendorID|tpep_pickup_datetime|tpep_dropoff_datetime|passenger_count|trip_distance|PULocationID|DOLocationID|fare_amount|extra|tip_amount|total_amount|airport_fee|TIP_STATUS|tpep_dropoff_datetime_index|tpep_pickup_datetime_index|            features|        prediction|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+------------------+\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:03|              1|          0.7|         142|          48|        5.0|  3.5|       0.0|         9.3|        0.0|         0|                     4356.0|                    7784.0|[1.0,0.7,0.0,142....| 6.829871118952641|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:04|              0|          0.9|         230|         186|        5.0|  3.0|       2.0|        10.8|        0.0|         1|                     4876.0|                    7784.0|[0.0,0.9,0.0,230....| 7.239666603704055|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:05|              1|          0.9|         162|         137|        6.0|  3.0|      1.95|       11.75|        0.0|         1|                     5144.0|                    7784.0|[1.0,0.9,0.0,162....| 7.260228843901214|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:07|              1|          1.1|         237|         236|        7.0|  3.0|      1.25|       12.05|        0.0|         1|                     5683.0|                    7784.0|[1.0,1.1,0.0,237....| 7.688220328587425|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:08|              1|          1.5|         162|         142|        8.0|  3.0|       2.2|        14.0|        0.0|         1|                     5684.0|                    7784.0|[1.0,1.5,0.0,162....|  8.82577461961405|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:09|              1|          1.0|          90|         158|        7.0|  3.0|      2.15|       12.95|        0.0|         1|                     3863.0|                    7784.0|[1.0,1.0,0.0,90.0...| 7.609477342529199|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:12|              2|          2.0|         249|         234|       10.0|  3.0|      2.75|       16.55|        0.0|         1|                     4877.0|                    7784.0|[2.0,2.0,0.0,249....|10.132867685776771|\n",
      "|       1|    02-01-2022 20:00|     02-01-2022 20:24|              1|          3.6|         239|         161|       17.0|  3.0|      4.15|       24.95|        0.0|         1|                     6760.0|                    7784.0|[1.0,3.6,0.0,239....|14.337578003269218|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:08|              1|          1.4|         170|          79|        6.5|  3.0|      2.05|       12.35|        0.0|         1|                     5684.0|                    6503.0|[1.0,1.4,0.0,170....| 8.624097531893051|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:22|              1|          4.0|         113|         239|       14.5|  3.0|      3.65|       21.95|        0.0|         1|                     5409.0|                    6503.0|[1.0,4.0,0.0,113....| 15.50217781123574|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:26|              0|         10.3|         138|         239|       31.0| 4.25|       8.4|        50.5|       1.25|         1|                     6761.0|                    6503.0|[0.0,10.3,1.25,13...| 32.07035874312297|\n",
      "|       1|    02-01-2022 20:01|     02-01-2022 20:41|              1|          5.4|         237|         116|       28.5|  3.0|       0.0|        32.3|        0.0|         0|                     6496.0|                    6503.0|[1.0,5.4,0.0,237....|19.215606033657373|\n",
      "|       1|    02-01-2022 20:02|     02-01-2022 20:07|              1|          1.0|          50|         186|        6.0|  3.5|      2.05|       12.35|        0.0|         1|                     5683.0|                    5412.0|[1.0,1.0,0.0,50.0...| 7.547949024736084|\n",
      "|       1|    02-01-2022 20:02|     02-01-2022 20:07|              1|          1.0|          68|          90|        5.5|  3.0|       2.3|        11.6|        0.0|         1|                     5683.0|                    5412.0|[1.0,1.0,0.0,68.0...| 7.598793767185676|\n",
      "|       1|    02-01-2022 20:02|     02-01-2022 20:10|              1|          1.7|         211|          68|        8.0|  3.0|       0.0|        11.8|        0.0|         0|                     4357.0|                    5412.0|[1.0,1.7,0.0,211....| 9.530166713230312|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:05|              1|          0.5|          50|          50|        3.5|  3.0|      1.45|        8.75|        0.0|         1|                     5144.0|                    4899.0|[1.0,0.5,0.0,50.0...| 6.336422743804173|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:06|              1|          0.5|          87|         231|        4.0|  3.0|       0.0|         7.8|        0.0|         0|                     4605.0|                    4899.0|[1.0,0.5,0.0,87.0...| 6.258239945050619|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:10|              3|          1.3|         239|         230|        6.5|  3.0|       3.0|        13.3|        0.0|         1|                     4357.0|                    4899.0|[3.0,1.3,0.0,239....| 8.365000493612953|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:11|              1|          1.2|          68|          48|        7.5|  3.0|      2.25|       13.55|        0.0|         1|                     6492.0|                    4899.0|[1.0,1.2,0.0,68.0...| 8.119363197177716|\n",
      "|       1|    02-01-2022 20:03|     02-01-2022 20:15|              1|          5.3|          87|         229|       16.0|  3.0|       4.5|        24.3|        0.0|         1|                     6228.0|                    4899.0|[1.0,5.3,0.0,87.0...| 18.97216147409055|\n",
      "+--------+--------------------+---------------------+---------------+-------------+------------+------------+-----------+-----+----------+------------+-----------+----------+---------------------------+--------------------------+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = fit_model.transform(test_data)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "090f20b8-ee80-4a14-9cd9-63ec188ec069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|fare_amount|        prediction|\n",
      "+-----------+------------------+\n",
      "|        5.0| 6.829871118952641|\n",
      "|        5.0| 7.239666603704055|\n",
      "|        6.0| 7.260228843901214|\n",
      "|        7.0| 7.688220328587425|\n",
      "|        8.0|  8.82577461961405|\n",
      "|        7.0| 7.609477342529199|\n",
      "|       10.0|10.132867685776771|\n",
      "|       17.0|14.337578003269218|\n",
      "|        6.5| 8.624097531893051|\n",
      "|       14.5| 15.50217781123574|\n",
      "|       31.0| 32.07035874312297|\n",
      "|       28.5|19.215606033657373|\n",
      "|        6.0| 7.547949024736084|\n",
      "|        5.5| 7.598793767185676|\n",
      "|        8.0| 9.530166713230312|\n",
      "|        3.5| 6.336422743804173|\n",
      "|        4.0| 6.258239945050619|\n",
      "|        6.5| 8.365000493612953|\n",
      "|        7.5| 8.119363197177716|\n",
      "|       16.0| 18.97216147409055|\n",
      "+-----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(['fare_amount','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18991818-9b72-4028-929d-2be8ae96ca07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b42ebec-34ca-4a2f-9ccb-faf9bb75b1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "test_results = fit_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca17849a-b081-4be0-aece-2405fedf6f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           residuals|\n",
      "+--------------------+\n",
      "| -1.8298711189526413|\n",
      "| -2.2396666037040553|\n",
      "| -1.2602288439012144|\n",
      "| -0.6882203285874251|\n",
      "| -0.8257746196140499|\n",
      "| -0.6094773425291988|\n",
      "|-0.13286768577677144|\n",
      "|  2.6624219967307816|\n",
      "| -2.1240975318930513|\n",
      "| -1.0021778112357396|\n",
      "| -1.0703587431229735|\n",
      "|   9.284393966342627|\n",
      "| -1.5479490247360843|\n",
      "| -2.0987937671856756|\n",
      "| -1.5301667132303116|\n",
      "| -2.8364227438041727|\n",
      "| -2.2582399450506188|\n",
      "| -1.8650004936129534|\n",
      "| -0.6193631971777158|\n",
      "| -2.9721614740905515|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_results.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "725744d0-4aa8-4c2d-baf7-8fa73f2f04f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:     6.091\n",
      "Ex Var:  98.249\n",
      "MAE:      2.116\n",
      "MSE:     37.100\n",
      "RMSE:     6.091\n",
      "R2:       0.729\n"
     ]
    }
   ],
   "source": [
    "print(f\"{'RMSE:':7s} {test_results.rootMeanSquaredError:>7.3f}\")\n",
    "print(f\"{'Ex Var:':7s} {test_results.explainedVariance:>7.3f}\")\n",
    "print(f\"{'MAE:':7s} {test_results.meanAbsoluteError:>7.3f}\")\n",
    "print(f\"{'MSE:':7s} {test_results.meanSquaredError:>7.3f}\")\n",
    "print(f\"{'RMSE:':7s} {test_results.rootMeanSquaredError:>7.3f}\")\n",
    "print(f\"{'R2:':7s} {test_results.r2:>7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d7d57d-ef27-47cc-a7bc-9542ec9f15f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0890541-2b97-41d9-8c69-250659feb7fc",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b943f2-b663-4603-a6ad-a141a27d86bb",
   "metadata": {},
   "source": [
    "Whether a taxi trip results in a tip or not. Here's a modified version of your code for logistic regression:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "831ba887-0036-45be-a052-7ede5da2e9f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91175c22-7155-4918-9fb1-b4bc9b9a8612",
   "metadata": {},
   "source": [
    "trip.printSchema()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b878917-de7c-4285-9fc0-1d37ed755bb6",
   "metadata": {},
   "source": [
    "# Define categorical and numeric columns\n",
    "categorical_columns = ['VendorID', 'PULocationID', 'DOLocationID']\n",
    "numeric_columns = ['passenger_count', 'trip_distance', 'extra', 'airport_fee']"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ec2f22f9-50f9-435c-b22c-ef9014bc5e71",
   "metadata": {},
   "source": [
    "# Use StringIndexer to convert the categorical columns to hold numerical data\n",
    "VendorID_indexer=StringIndexer(inputCol='VendorID', outputCol='VendorID_index',handleInvalid='keep')\n",
    "PULocationID_indexer=StringIndexer(inputCol='PULocationID', outputCol='PULocationID_index',handleInvalid='keep')\n",
    "DOLocationID_indexer=StringIndexer(inputCol='DOLocationID', outputCol='DOLocationID_index',handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "46f76192-b476-49c9-99ac-4d2c233c6336",
   "metadata": {},
   "source": [
    "from pyspark.ml.feature import OneHotEncoder"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a414ac6-7cf5-4766-a19e-e8acc390ece6",
   "metadata": {},
   "source": [
    "data_encoder = OneHotEncoder(\n",
    "    inputCols=[\n",
    "        'VendorID_index',\n",
    "        'PULocationID_index',\n",
    "        'DOLocationID_index'\n",
    "    ], \n",
    "    outputCols= [\n",
    "        'VendorID_vec',\n",
    "        'PULocationID_vec',\n",
    "        'DOLocationID_vec'],\n",
    "    handleInvalid='keep'\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1024372b-534a-4516-bfe5-21e9fe97e6e7",
   "metadata": {},
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'VendorID_vec',\n",
    "        'PULocationID_vec',\n",
    "        'DOLocationID_vec','passenger_count', 'trip_distance', 'extra', 'airport_fee'\n",
    "        ],\n",
    "    outputCol=\"features_log\"\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26b088ab-890e-4698-a35e-1dc16b58f64d",
   "metadata": {},
   "source": [
    "lr_model=LogisticRegression(labelCol='TIP_STATUS')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "585e37ee-2dc0-4961-9bd6-939dc71196ef",
   "metadata": {},
   "source": [
    "pipe = Pipeline(\n",
    "    stages=[\n",
    "        VendorID_indexer,\n",
    "    PULocationID_indexer,\n",
    "    DOLocationID_indexer,\n",
    "        data_encoder,\n",
    "        assembler,\n",
    "        lr_model\n",
    "    ]\n",
    ")\n",
    "  "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3a477849-08dd-4a40-bd58-0fc24e5533bb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "8c313506-1061-439f-9031-14b17b8605d5",
   "metadata": {},
   "source": [
    "# run the pipeline\n",
    "fit_model=pipe.fit(train_data)\n",
    "\n",
    "# Store the results in a dataframe\n",
    "results_log = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3800e3cd-44e2-4ea9-a02d-69040cf3638e",
   "metadata": {},
   "source": [
    "results_log.select(['TIP_STATUS','prediction']).show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f9c7f68f-273b-47da-a8f4-99f424a6b897",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e6b32ab-4e8c-46b5-bfc0-87849b5965a7",
   "metadata": {},
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "AUC_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='TIP_STATUS',metricName='areaUnderROC')\n",
    "\n",
    "AUC = AUC_evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c0528a56-47f8-468d-b817-037d6c4ba1a3",
   "metadata": {},
   "source": [
    "print(\"The area under the curve is {}\".format(AUC))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bfeb4015-df61-4580-b877-ba67427cb9d2",
   "metadata": {},
   "source": [
    "PR_evaluator = BinaryClassificationEvaluator(rawPredictionCol='prediction',labelCol='TIP_STATUS',metricName='areaUnderPR')\n",
    "PR = PR_evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "be5f6e07-ea58-41d6-8f72-7e0f3d477430",
   "metadata": {},
   "source": [
    "print(\"The area under the PR curve is {}\".format(PR))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c8f4de81-d2a4-4071-a049-1032df8119c3",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "raw",
   "id": "07bccd02-e584-4302-bd44-b9c970b8f7d6",
   "metadata": {},
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "ACC_evaluator = MulticlassClassificationEvaluator(  #  Multiclass or Binary, the accuracy is calculated in the same way.\n",
    "    labelCol=\"TIP_STATUS\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = ACC_evaluator.evaluate(results)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb07f9a1-e7f2-473b-976d-2b85ada899ad",
   "metadata": {},
   "source": [
    "print(\"The accuracy of the model is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d6cd6f6-486c-4e5b-8c9b-99f0d029ef82",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "593cb949-8b03-409f-8210-d41afa277435",
   "metadata": {},
   "source": [
    "y_true = results.select(\"TIP_STATUS\")\n",
    "y_true = y_true.toPandas()\n",
    " \n",
    "y_pred = results.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    " \n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ee0ef6d-d87e-446d-8d7c-fdb49f26908b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be7d010a-2b97-473d-bf27-36b12d3e7692",
   "metadata": {},
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e378997-dbfd-4aa6-a2eb-bc8b004b81aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.feature import VectorAssembler,StringIndexer\n",
    "from pyspark.ml import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "198f3fb6-5d3f-4db0-8663-b61f03055030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use StringIndexer to convert the categorical columns to hold numerical data\n",
    "VendorID_indexer=StringIndexer(inputCol='VendorID', outputCol='VendorID_index',handleInvalid='keep')\n",
    "PULocationID_indexer=StringIndexer(inputCol='PULocationID', outputCol='PULocationID_index',handleInvalid='keep')\n",
    "DOLocationID_indexer=StringIndexer(inputCol='DOLocationID', outputCol='DOLocationID_index',handleInvalid='keep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f220c7f9-9702-42bb-970a-2c5023285817",
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'VendorID_index',\n",
    "        'PULocationID_index',\n",
    "        'DOLocationID_index',\n",
    "        'passenger_count', 'trip_distance', 'extra', 'airport_fee'\n",
    "    ],\n",
    "    outputCol=\"features_dtree\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "51cc03e6-7cb5-4e8b-9ca9-c5a0c5c99a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeClassifier(labelCol='TIP_STATUS',maxBins=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bdd9ba8-3a8f-469c-ada5-a765c1cb56a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    stages=[\n",
    "        VendorID_indexer,\n",
    "        PULocationID_indexer,\n",
    "        DOLocationID_indexer,\n",
    "        assembler,\n",
    "        dt_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9230da82-7173-4e07-a617-a2d1b867e7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "fit_model=pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f2689ea5-e36f-4f50-8527-9cea375bdded",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa78255a-dadb-440c-af78-18351cfba9e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|TIP_STATUS|prediction|\n",
      "+----------+----------+\n",
      "|         0|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         0|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         0|       1.0|\n",
      "|         1|       1.0|\n",
      "|         0|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "|         1|       1.0|\n",
      "+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results.select(['TIP_STATUS','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aa752e84-03aa-499c-b9e2-2563e41fc93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bde5489b-a402-4f20-9ef2-bbe404aeef1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 52:=================>                                      (5 + 11) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the decision tree classifier is 0.7700212943245995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "ACC_evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"TIP_STATUS\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "accuracy = ACC_evaluator.evaluate(results)\n",
    "\n",
    "print(f\"The accuracy of the decision tree classifier is {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa84263-fd8e-4790-b7a1-3a977218af58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
