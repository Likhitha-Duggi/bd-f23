{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6963b70e-2713-4600-8fa1-8f010df44ed7",
   "metadata": {},
   "source": [
    "# Team Name : Hadoop Heros \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e292f0-f9fe-4b1a-ac14-a9b497382e19",
   "metadata": {},
   "source": [
    "### Importing libraries and creating spark context "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec40f5b-20d3-4fd8-a140-37eb1ac7605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.conf import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6886c32-b7d1-462b-a59d-2d54e12075e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/10 14:36:17 WARN Utils: Your hostname, localhost.localdomain resolves to a loopback address: 127.0.0.1; using 10.21.10.196 instead (on interface eth0)\n",
      "23/11/10 14:36:17 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/10 14:36:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "#datawarehouse_location points to the default location for managed databases and tables\n",
    "from os.path import abspath\n",
    "warehouse_location = abspath('spark-warehouse')\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"ISM6562 Spark Project\") \\\n",
    "        .enableHiveSupport() \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark_session_port = spark.sparkContext.uiWebUrl.split(\":\")[-1]\n",
    "print(\"Spark Session WebUI Port: \" + spark_session_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94ff0d-19b6-4393-af94-c2cb2371f31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d14593-b6f6-497e-9ebf-dba56d7c426c",
   "metadata": {},
   "source": [
    "## Load data to spark dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3489589-7f06-4e63-840f-82369b7da5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = spark.read.csv('data/yellow_tripdata_2022-02.csv' , header = True , inferSchema=True)\n",
    "\n",
    "# display the first 10 rows of the dataframe \n",
    "trips.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debbb973-8afc-4909-b21f-aa8584e233ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d0a620-8162-4f69-a9dd-efc39b25bbe6",
   "metadata": {},
   "source": [
    "## Data-preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33076401-df5f-4798-a81b-7952435da69d",
   "metadata": {},
   "source": [
    "Create a database and table in spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301162ab-4760-406c-a07b-ddff5094d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.createOrReplaceTempView(\"trips_tmp_view\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7ee74a-31fc-47ff-a6f0-af839804fbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= spark.sql(\"SELECT * FROM trips_tmp_view\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c17089-663f-4e4d-9f32-1fa031a5c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e97fc97-0e77-4a58-84e6-aeb2cd659848",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS trips_db;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83572586-5285-4ce3-a93b-4b68d0dcbfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.write.mode(\"overwrite\").saveAsTable(\"trips_db.trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d4d18-333d-46e9-b76d-e4d939d068c1",
   "metadata": {},
   "source": [
    "Listing tables in the created database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c96b81-a5e7-4ca3-8d52-7da53fa23504",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.listTables('trips_db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ed0b4b-1ce5-4e0a-9e8d-dcb66b6d63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\"SELECT * FROM trips_db.trips\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191fdeb-d330-442d-91a9-1eecf996d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.sql(\" describe trips_db.trips\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f081b31-c4cc-4ce8-9aa8-6c3812bf019a",
   "metadata": {},
   "source": [
    "# Data Exploration using PySpark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1c60ca-7aaf-40dc-9fe7-cd2ca47c5b2b",
   "metadata": {},
   "source": [
    "### Number of Trips by VendorID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e7b8ed-051c-4701-8942-756f75764bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vendor1_trips = spark.sql(\"\"\"SELECT COUNT(VendorID) as vendorID1 \n",
    "    FROM trips_db.trips \n",
    "    WHERE VendorID=1\"\"\")\n",
    "\n",
    "vendor1_trips_1=vendor1_trips.first().vendorID1\n",
    "\n",
    "print(\"Number of trips taken by Vendor 1:\", vendor1_trips_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca31f3-d6ca-4f0d-b1f3-781ab91baf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vendor2_trips = spark.sql(\"\"\"SELECT COUNT(VendorID) as vendorID2 \n",
    "    FROM trips_db.trips \n",
    "    WHERE VendorID=2\"\"\")\n",
    "\n",
    "vendor2_trips_2=vendor2_trips.first().vendorID2\n",
    "\n",
    "print(\"Number of trips taken by Vendor 2:\", vendor2_trips_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e344020-675b-45aa-94c0-408e3f1653b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the result to Pandas for easy plotting\n",
    "vendor1_count = vendor1_trips.toPandas()['vendorID1'][0]\n",
    "vendor2_count = vendor2_trips.toPandas()['vendorID2'][0]\n",
    "\n",
    "# Plotting the bar chart\n",
    "vendors = ['VendorID 1', 'VendorID 2']\n",
    "counts = [vendor1_count, vendor2_count]\n",
    "\n",
    "plt.bar(vendors, counts, color=['blue', 'green'])\n",
    "plt.title('Number of Trips for VendorID 1 and VendorID 2')\n",
    "plt.xlabel('VendorID')\n",
    "plt.ylabel('Number of Trips')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a400ca-9567-459d-a501-61836ea92a33",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "Vendor1 and Vendor2 had 319007, 724578 trips each in total\n",
    "Vendor2 took more than twice the number of trips of Vendor1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cc9ecf-90b7-460e-b194-2775ca344c75",
   "metadata": {},
   "source": [
    "### Number of trips by pickup and dropff location "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00c9da14-a388-49a4-842c-b71b8f621280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of each pickup location \n",
    "\n",
    "pickup_trips = spark.sql(\"\"\"SELECT PULocationID, COUNT(*) AS pickup_count \n",
    "    FROM trips_db.trips \n",
    "    GROUP BY PULocationID\n",
    "    ORDER BY pickup_count DESC\"\"\")\n",
    "\n",
    "# Convert the DataFrame to a Pandas DataFrame\n",
    "pickup_trips_pandas = pickup_trips.toPandas()\n",
    "\n",
    "# Print the Pandas DataFrame\n",
    "print(pickup_trips_pandas.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b50bdd-3b0a-469d-aa0b-c65d3d8ab8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of each dropoff location \n",
    "\n",
    "dropoff_trips = spark.sql(\"\"\"SELECT DOLocationID, COUNT(*) AS dropoff_count \n",
    "    FROM trips_db.trips\n",
    "    GROUP BY DOLocationID \n",
    "    ORDER BY dropoff_count DESC\"\"\")\n",
    "\n",
    "# Convert the DataFrame to a Pandas DataFrame\n",
    "dropoff_trips_pandas = dropoff_trips.toPandas()\n",
    "\n",
    "# Print the Pandas DataFrame\n",
    "print(dropoff_trips_pandas.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d0186-c62d-417c-8cd0-23aa36857611",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "The most frequented pick up and drop off location are  Taxi Zones 237 & 236"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5140b1e3-aef3-4957-8bc7-cd660dfdd124",
   "metadata": {},
   "source": [
    "### Which vendor provides a better service? \n",
    "(Assumption : Tipping being a metric for good service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9404a2c8-82ec-4226-97a7-fc7399bfb86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_tip_per_vendor = spark.sql(\"\"\"SELECT VendorID, ROUND(AVG(tip_amount),2) AS avg_tip \n",
    "    FROM trips_db.trips \n",
    "    GROUP BY VendorID \n",
    "    ORDER BY avg_tip DESC \"\"\")\n",
    "\n",
    "avg_tip_per_vendor_pandas=avg_tip_per_vendor.toPandas()\n",
    "print(avg_tip_per_vendor_pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa8a9e9-fbc8-4859-9c4a-4a4f0ebd032b",
   "metadata": {},
   "source": [
    "Analysis:\n",
    "\n",
    "The avg_tip difference between both vendors is minimal.\n",
    "Based on this result, it is difficult to draw a conclusion on service quality."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7115d73-519e-41a9-a5ab-c5801ff5af6d",
   "metadata": {},
   "source": [
    "### What is the average fare for the trips during rush hours with extra charges? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7636ed69-65b0-4aaa-91d5-5d16dac6b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_fare_amount_rush_hour = spark.sql(\"\"\"SELECT ROUND(AVG(fare_amount),3) as avg_fare_amount \n",
    "    FROM trips_db.trips \n",
    "    WHERE extra > 0\"\"\")\n",
    "\n",
    "# Extract the average fare amount value\n",
    "average_fare = avg_fare_amount_rush_hour.first()[0]\n",
    "\n",
    "# Print the statement\n",
    "print(f\"Average Fare  for trips during rush hours is: ${average_fare:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9e84a-785b-48ee-8c16-f4dc4c29299b",
   "metadata": {},
   "source": [
    "### What is the average total amount collected for trips with more than 2 passengers ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c096d012-f604-4417-8638-1a7ceddd6c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_total_for_large_groups = spark.sql(\"\"\"SELECT ROUND(AVG(total_amount),2) as total_fare \n",
    "    FROM trips_db.trips  \n",
    "    WHERE passenger_count > 2\"\"\")\n",
    "\n",
    "# Extract the average fare amount value\n",
    "average_total = avg_total_for_large_groups.first()[0]\n",
    "\n",
    "# Print the statement\n",
    "print(f\"Average total amount for trips with more than 2 passengers: ${average_total:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f296b6c-6a5e-4a21-8c1e-926f8dd6ebba",
   "metadata": {},
   "source": [
    "### What is the avergare trip distance for each passenger count? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02432bd3-06e0-47b9-a245-69b08c7e5c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_distance_per_passenger = spark.sql(\"\"\"SELECT passenger_count, ROUND(AVG(trip_distance),2) as avg_distance \n",
    "    FROM trips_db.trips \n",
    "    GROUP BY passenger_count\n",
    "    ORDER BY passenger_count\"\"\")\n",
    "\n",
    "avg_distance_per_passenger_pandas = avg_distance_per_passenger.toPandas()\n",
    "print(avg_distance_per_passenger_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4be7b1a-5a2b-4043-8aac-fa56bd14c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.bar(avg_distance_per_passenger_pandas['passenger_count'], avg_distance_per_passenger_pandas['avg_distance'], color='lightgreen', alpha=0.7)\n",
    "plt.xlabel('Passenger Count')\n",
    "plt.ylabel('Average Distance')\n",
    "plt.title('Average Distance per Passenger Count')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645cd378-8fab-437f-a5e3-52c2d885026c",
   "metadata": {},
   "source": [
    "### What is the relation between trip distance and fare amount ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbd5181-ab8e-4ee6-b477-178c64dec3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips_pd = trips.toPandas()\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(trips_pd['trip_distance'], trips_pd['fare_amount'], alpha=0.5)\n",
    "plt.title('Trip distance Vs Fare amount')\n",
    "plt.xlabel('Trip Distance (miles)')\n",
    "plt.ylabel('Fare Amount ($)')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4afdd9e-a182-4177-ac47-e19e777bb19e",
   "metadata": {},
   "source": [
    "Analysis\n",
    "\n",
    "From the above scatter plot, general trend seems to increase in fare amount for every additional mile travelled . \n",
    "Negative fares might represent refund amount for cancelled trips.\n",
    "Zero fare amount for distance travelled may represnt promotional offers for the ride. \n",
    "Fare amounts for zero distance travelled might be cancellation of trips after late cancellation or minimum fare charged regardless of distance travelled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df7039d-3818-4e56-a257-ebaaf5e85254",
   "metadata": {},
   "source": [
    "## Understanding the data structure and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771ec18-b2bc-41de-b338-46133842f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreving column names\n",
    "trips.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46049d1-e351-4a5f-874c-85ee15360487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of rows\n",
    "num_rows = trips.count()\n",
    "\n",
    "#  number of columns\n",
    "num_columns = len(trips.columns)\n",
    "\n",
    "print(\"Number of rows: {}\".format(num_rows))\n",
    "print(\"Number of columns: {}\".format(num_columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73154c0-9de3-40c6-8b35-6351230aa521",
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a755c4-9fbb-4c61-ab2f-7063edd5b896",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Extracting required columns for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63945e58-b2f7-47dd-ab4d-5b0119cb1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['VendorID', 'passenger_count', 'trip_distance', 'PULocationID', 'DOLocationID', 'fare_amount', 'extra', 'airport_fee']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8149d566-cb5a-4f1f-8cfc-55432abfe34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data = trips.select(selected_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6498c8f-730a-42d0-aea7-5613576a4ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rowns with any null values \n",
    "selected_data = selected_data.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7874a3f0-737b-4c12-a029-d42fc9fbdaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b10ac95-f7f7-4922-bb61-ad69204658c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting VendorID, PULocationID, DOLocationID, airport_fee to categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96de1d1d-f9dc-42f2-90ec-0b8797267d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType\n",
    "\n",
    "selected_data = selected_data.withColumn(\"VendorID\",selected_data.VendorID.cast(StringType()))\n",
    "selected_data = selected_data.withColumn(\"PULocationID\",selected_data.PULocationID.cast(StringType()))\n",
    "selected_data = selected_data.withColumn(\"DOLocationID\",selected_data.DOLocationID.cast(StringType()))\n",
    "selected_data = selected_data.withColumn(\"airport_fee\",selected_data.airport_fee.cast(StringType()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b0e88-8785-46f9-960d-01c223fb7cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922cd898-8805-495f-a0aa-8de9f83ed370",
   "metadata": {},
   "source": [
    "Now that we have our data ready, let's do a train test split (70/30)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61fcb05-1fab-479f-93d8-b856bef6cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data,test_data=selected_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa1cf13-9635-4396-852e-6b19d450b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "# Use StringIndexer to convert the categorical columns to hold numerical data\n",
    " \n",
    "VendorID_indexer = StringIndexer(inputCol='VendorID',outputCol='VendorID_index',handleInvalid='keep')\n",
    "PULocationID_indexer = StringIndexer(inputCol='PULocationID',outputCol='PULocationID_index',handleInvalid='keep')\n",
    "DOLocationID_indexer = StringIndexer(inputCol='DOLocationID',outputCol='DOLocationID_index',handleInvalid='keep')\n",
    "airport_fee_indexer = StringIndexer(inputCol='airport_fee',outputCol='airport_fee_index',handleInvalid='keep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a69e92b-e8c3-4a6a-99e1-739a0746bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "# Vector assembler is used to create a vector of input features\n",
    " \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\n",
    "        'VendorID_index',\n",
    "        'PULocationID_index',\n",
    "        'DOLocationID_index',\n",
    "        'airport_fee_index',\n",
    "        'extra',\n",
    "        'trip_distance',\n",
    "        'passenger_count',\n",
    "    ],\n",
    "    outputCol=\"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b207cb2-120f-4c8b-8dcc-49c9dc03cff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Pipeline is used to pass the data through indexer and assembler simultaneously. Also, it helps to pre-rocess the test data\n",
    "# in the same way as that of the train data\n",
    "\n",
    " \n",
    "pipe = Pipeline(stages=[\n",
    "    VendorID_indexer,\n",
    "    PULocationID_indexer,\n",
    "    DOLocationID_indexer,\n",
    "    airport_fee_indexer,\n",
    "    assembler\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d200981f-d962-48bf-9b1d-c03ed408407e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted_pipe=pipe.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef5e25-4ca6-49ee-988f-f3d5ec07fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=fitted_pipe.transform(train_data)\n",
    "train_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36790e02-eebe-4f15-9eeb-2c33989bc0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=fitted_pipe.transform(test_data)\n",
    "test_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0f9d01-196e-4a3a-bc71-bc4d68d94b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "lr_model = LinearRegression(labelCol='fare_amount')\n",
    "fit_model = lr_model.fit(train_data.select(['features','fare_amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa57dce-de84-4eab-9be6-3f7c77aab9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fit_model.transform(test_data)\n",
    "results.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ed4c6-7732-4fea-bad0-4f811687b56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.select(['fare_amount','prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8107536e-0583-4149-9704-dea9dbfcd77f",
   "metadata": {},
   "source": [
    "## Evaluate the peformance of the Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34af6105-a107-4479-82e2-ad652237d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_lr = fit_model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf26678-cb40-4a01-ba13-9316503de2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_lr.residuals.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61467348-c53d-4f2b-80ab-27fd7c315ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_linear=test_results_lr.rootMeanSquaredError\n",
    "r2_linear=test_results_lr.r2\n",
    "\n",
    "print(f\"{'RMSE LinearReg:':7s} {test_results_lr.rootMeanSquaredError:>7.3f}\")\n",
    "print(f\"{'MAE LinearReg:':7s} {test_results_lr.meanAbsoluteError:>7.3f}\")\n",
    "print(f\"{'MSE LinearReg:':7s} {test_results_lr.meanSquaredError:>7.3f}\")\n",
    "print(f\"{'R2 LinearReg:':7s} {test_results_lr.r2:>7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0f48e-48ce-4b3b-a2dc-ea75da3c8983",
   "metadata": {},
   "source": [
    "## Decision Tree "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2636f-553e-4cad-8549-f8d8cdc99676",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import  DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d98977-7750-4d6a-b85c-c8f332b66bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = DecisionTreeRegressor(labelCol='fare_amount',maxBins=5000)\n",
    "fit_model = dt_model.fit(train_data.select(['features','fare_amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69cab2fd-7cef-4109-bf49-2268d81531b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(\n",
    "    stages=[\n",
    "        VendorID_indexer,\n",
    "        PULocationID_indexer,\n",
    "        DOLocationID_indexer,\n",
    "        airport_fee_indexer,\n",
    "        assembler,\n",
    "        dt_model\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83cb63e-92d5-4ad0-bd49-7264ff752bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dt = fit_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c17cca-6ca5-4327-9a62-2aa317459cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dt.select(['fare_amount','prediction']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e471e-3128-4c5b-a5f2-1f0db2b66bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "# Define the evaluator\n",
    "evaluator = RegressionEvaluator(labelCol=\"fare_amount\", predictionCol=\"prediction\")\n",
    "\n",
    "# Calculate the metrics\n",
    "rmse_dtree = evaluator.evaluate(results_dt, {evaluator.metricName: \"rmse\"})\n",
    "mae_dtree = evaluator.evaluate(results_dt, {evaluator.metricName: \"mae\"})\n",
    "mse_dtree = evaluator.evaluate(results_dt, {evaluator.metricName: \"mse\"})\n",
    "r2_dtree = evaluator.evaluate(results_dt, {evaluator.metricName: \"r2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215bf651-6275-44ea-8fc2-42e5789303fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the metrics\n",
    "print(f\"{'RMSE Dtree:':7s} {rmse_dtree:>7.3f}\")\n",
    "print(f\"{'MAE Dtree:':7s} {mae_dtree:>7.3f}\")\n",
    "print(f\"{'MSE Dtree:':7s} {mse_dtree:>7.3f}\")\n",
    "print(f\"{'R2 Dtree:':7s} {r2_dtree:>7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94b217a-4337-4cc1-a10e-51c828093171",
   "metadata": {},
   "source": [
    "## RANDOM FOREST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003396a5-9a49-4a52-a0c0-d3aabf2ef3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "# Random Forest model\n",
    "rf_model = RandomForestRegressor(labelCol='fare_amount', featuresCol='features', numTrees=100, maxBins=260)\n",
    "fit_model = rf_model.fit(train_data.select(['features','fare_amount']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf2a95b-eb74-43e7-8ab2-f0db2e666bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "\n",
    "results_rf = fit_model.transform(test_data)\n",
    "results_rf.select(['fare_amount', 'prediction']).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975c588a-1147-4422-8762-9cdd9da16b24",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604df2f-0afd-48f8-8bf5-d91501b25868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Random Forest model\n",
    "evaluator = RegressionEvaluator(labelCol=\"fare_amount\", predictionCol=\"prediction\")\n",
    "\n",
    "rmse_rf = evaluator.evaluate(results_rf, {evaluator.metricName: \"rmse\"})\n",
    "mae_rf = evaluator.evaluate(results_rf, {evaluator.metricName: \"mae\"})\n",
    "mse_rf = evaluator.evaluate(results_rf, {evaluator.metricName: \"mse\"})\n",
    "r2_rf = evaluator.evaluate(results_rf, {evaluator.metricName: \"r2\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca85393-6a3e-412d-9a49-deabe000e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'RMSE (Random Forest):':22s} {rmse_rf:>7.3f}\")\n",
    "print(f\"{'MAE (Random Forest):':22s} {mae_rf:>7.3f}\")\n",
    "print(f\"{'MSE (Random Forest):':22s} {mse_rf:>7.3f}\")\n",
    "print(f\"{'R2 (Random Forest):':22s} {r2_rf:>7.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8db8b1-4f78-466d-8819-d6dcf4a02579",
   "metadata": {},
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3f4fc02-5ea7-40bd-b1ef-6fe206bd8a62",
   "metadata": {},
   "source": [
    "We built 3 models for predicting the fare price based on the input features like VendorID, Pickup location and drop off location ID's, airport fee, extra charges, total trip distance, and passenger count.\n",
    "\n",
    "Upon evaluating metrics, these are the results:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f7ea14-76e1-422a-8b49-27cf00d30a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{'Linear regression Model'}\")\n",
    "print(f\"{'RMSE :':22s}{rmse_linear:>7.3f}\")\n",
    "print(f\"{'R-squared error :':22s}{r2_linear:>7.3f}\")\n",
    "\n",
    "print(\"*****************************\")\n",
    "print(f\"{'Decision Tree Model'}\")\n",
    "print(f\"{'RMSE :':22s}{rmse_dtree:>7.3f}\")\n",
    "print(f\"{'R-squared error:':22s}{r2_dtree:>7.3f}\")\n",
    "\n",
    "print(\"*****************************\")\n",
    "print(f\"{'Random Forest Model'}\")\n",
    "print(f\"{'RMSE :':22s}{rmse_rf:>7.3f}\")\n",
    "print(f\"{'R-squared error :':22s}{r2_rf:>7.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12eb27b6-c1ea-461a-94e8-574ffb852914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758c43f3-2b13-40ab-a764-f08c9f8e2e5a",
   "metadata": {},
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268e3f4-ec14-414d-bd13-092ff8bcee11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
